{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_url(x=1980,y=2018): \n",
    "    if x > y :\n",
    "        raise ValueError('Start time should be earlier.')\n",
    "    if x < 1980 or y> int(str(datetime.datetime.now())[:4]):\n",
    "        raise ValueError('Please input time during 1980 till now.')\n",
    "    \n",
    "    url = 'https://www.boxofficemojo.com/yearly/'\n",
    "    url_list = []\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    results = BeautifulSoup(response.content, 'lxml')\n",
    "    results = results.find_all('a')\n",
    "    \n",
    "    for result in results:\n",
    "        if 'yr=' in result.get('href') and int(result.get_text())>=x and int(result.get_text())<=y:\n",
    "            url_list.append(url+result.get('href'))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie(url = None, year = None):\n",
    "    if url == None:\n",
    "        url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "    response = requests.get(url)\n",
    "    results = BeautifulSoup(response.content, 'lxml')\n",
    "    results = results.find_all('a')        \n",
    "    \n",
    "    url_list=[]\n",
    "    for result in results:\n",
    "        if result.get('href') != None:\n",
    "            if 'id='in result.get('href') and '#' not in result.get_text():\n",
    "                url_list.append('https://www.boxofficemojo.com'+result.get('href'))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(url = None, year = None):\n",
    "    if url == None:\n",
    "        url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "    response = requests.get(url)\n",
    "    results = BeautifulSoup(response.content, 'lxml')\n",
    "    results = results.find_all('a')        \n",
    "    \n",
    "    moviename_list=[]\n",
    "    for result in results:\n",
    "        if result.get('href') != None:\n",
    "            if 'id='in result.get('href') and '#' not in result.get_text():\n",
    "                moviename_list.append(result.get_text())\n",
    "    return moviename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dict of (movie_name, movie_url)\n",
    "def find_all(x,y):\n",
    "    list_url = get_movie_url(x,y)\n",
    "    dict_movie = {}\n",
    "    for url in list_url:\n",
    "        list_0 = dict_movie.copy()\n",
    "        list_1 = dict(map(lambda x,y:[x,y],get_movie_name(url),get_movie(url)))\n",
    "        dict_movie = {**list_0, **list_1}\n",
    "    return dict_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a specifi movie's daily gross\n",
    "def gross_movie(name,begin_year=1980,end_year=2018):      \n",
    "    import pandas as pd\n",
    "    import requests \n",
    "    from bs4 import BeautifulSoup\n",
    "    try:\n",
    "        movie_url = find_all(begin_year,end_year)[name]\n",
    "        id_position = movie_url.find('id=')\n",
    "        name_id = movie_url[id_position:]\n",
    "        url = 'https://www.boxofficemojo.com/movies/?page=daily&view=chart&'+name_id\n",
    "        response = requests.get(url)\n",
    "        results = BeautifulSoup(response.content, 'lxml')\n",
    "        tables = results.select('table')\n",
    "        df_list = []\n",
    "        for table in tables:\n",
    "            df_list.append(pd.concat(pd.read_html(table.prettify())))\n",
    "        movie_gross = df_list[7]\n",
    "        movie_gross.columns = ['Day','Date','Rank','Gross','%daily-change','%weekly-change','Theaters','Average','Gross-to-Date','Days']\n",
    "        movie_gross = movie_gross[(movie_gross['Date'] != 'Date') & (movie_gross['Date'].notnull())]\n",
    "        movie_gross.set_index('Date',inplace=True)\n",
    "        movie_gross[['Days']] = movie_gross[['Days']].astype(int)\n",
    "        return movie_gross        \n",
    "    except:\n",
    "        ValueError(f'{name} is not in the TOP100 of year from to {begin_year} to {end_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # a specifi movie's basic information\n",
    "def data_movie(name,begin_year=1980,end_year=2018):      \n",
    "    import pandas as pd\n",
    "    import requests \n",
    "    from bs4 import BeautifulSoup\n",
    "    try:\n",
    "        movie_url = find_all(begin_year,end_year)[name]\n",
    "        response = requests.get(movie_url)\n",
    "        results = BeautifulSoup(response.content, 'lxml')\n",
    "        tables = results.select('table')\n",
    "        df_list = []\n",
    "        for table in tables:\n",
    "            df_list.append(pd.concat(pd.read_html(table.prettify())))\n",
    "        movie_info = {}\n",
    "        movie_info['Name'] = name\n",
    "        \n",
    "        movie_info['Genre'] = df_list[5][0].iloc[2][8:]\n",
    "        movie_info['Runtime'] = df_list[5][1].iloc[2][10:]\n",
    "        movie_info['Production Budget'] = df_list[5][1].iloc[3][20:]\n",
    "        \n",
    "        movie_info['Domestic Gross'] = df_list[9][1].iloc[0]\n",
    "        try:\n",
    "            movie_info['Foreign Gross'] = df_list[9][1].iloc[1]\n",
    "        except:\n",
    "            movie_info['Foreign Gross'] = None\n",
    "        try:\n",
    "            movie_info['Worldwide Gross'] = df_list[9][1].iloc[3]\n",
    "        except:\n",
    "            movie_info['Worldwide Gross'] = None\n",
    "        \n",
    "        movie_info['Release Date'] = df_list[5][1].iloc[1][15:]\n",
    "    \n",
    "        for n in [12,13,14,15,16]:\n",
    "            if df_list[n][0].iloc[0] == 'In Release:':      \n",
    "                movie_info['Inrelease Time'] = df_list[n][1].iloc[0]\n",
    "                df_list[n+1].set_index(0,inplace=True)\n",
    "                \n",
    "                try:\n",
    "                    movie_info['Actors'] = df_list[n+1][1].loc['Actors:']\n",
    "                except:\n",
    "                    movie_info['Actors'] = None\n",
    "                \n",
    "                try:\n",
    "                    movie_info['Director'] = df_list[n+1][1].loc['Director:']\n",
    "                except:\n",
    "                    movie_info['Director'] = None   \n",
    "                \n",
    "                try:\n",
    "                    movie_info['Producer'] = df_list[n+1][1].loc['Producer:']\n",
    "                except:\n",
    "                    movie_info['Producer'] = None   \n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                n = n + 1\n",
    "   \n",
    "        movie_info['Distributor'] = df_list[5][0].iloc[1][14:]\n",
    "        \n",
    "        mv = pd.DataFrame(list(movie_info.items()))\n",
    "        mv.columns = ['Items',name]\n",
    "        mv.set_index('Items',inplace=True)\n",
    "#         mv.to_csv(path_or_buf=f'./{name}Basic_info.csv')\n",
    "        mv\n",
    "        return mv\n",
    "    except:\n",
    "        ValueError(f'{name} is not in the TOP100 of year from to {begin_year} to {end_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_list[5] = Distributor, Genre,MPAA Rating,Release Date,Runtime,Production Budget\n",
    "#df_list[9] = gross Domestic Foreign Worldwide\n",
    "#df_list[10] = opening weekend, opending weekend of total gross\n",
    "#df_list[11] = widest release of theaters\n",
    "#df_list[12] = close date\n",
    "#df_list[13] = inrelease time period\n",
    "#df_list[14] = Director, Actors, Producer, Cinematographer, Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_movies_table(begin_year=1980,end_year=2018,input_name=None):  \n",
    "    if not input_name == None:\n",
    "        name_list = input_name\n",
    "    else:\n",
    "        name_list = list(find_all(begin_year,end_year).keys())\n",
    "    movie_table = data_movie(name_list[0],begin_year,end_year)\n",
    "    for name in name_list[1:]:\n",
    "        try:\n",
    "            movie_info = data_movie(name,begin_year,end_year)\n",
    "            movie_table[name]=movie_info[name]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "#     mv.to_csv(path_or_buf=f'./{begin_year}-{end_year}some movies basic info.csv')\n",
    "    return movie_table.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(name, page_length = 2, num = 20):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    url = 'https://www.rottentomatoes.com/m/'+name+'/reviews/'\n",
    "    response = requests.get(url)\n",
    "    results_page = BeautifulSoup(response.content, 'lxml')\n",
    "    results = results_page.find_all('div', class_ = 'the_review')\n",
    "    page = 1\n",
    "    reviews = list()\n",
    "    next_page_results = list()\n",
    "\n",
    "    while page < page_length:\n",
    "        for item in results_page.find_all('a', class_ = 'btn btn-xs btn-primary-rt'):\n",
    "            if item.find('span', class_ = \"glyphicon glyphicon-chevron-right\"):\n",
    "                url = 'https://www.rottentomatoes.com' + item.get('href')\n",
    "                response = requests.get(url)\n",
    "                results_page = BeautifulSoup(response.content, 'lxml')\n",
    "                next_page_results = results_page.find_all('div', class_ = 'the_review')\n",
    "                results.extend(next_page_results)\n",
    "                page+=1\n",
    "                for result in results:\n",
    "                    reviews.append(result.get_text())\n",
    "\n",
    "    return reviews[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_review(year, num = 30, page_length = 2, length = 20):\n",
    "    movies = get_movie_name(None, year)\n",
    "    for i in range(len(movies)):\n",
    "        movies[i] = movies[i].lower().replace(' ', '_').replace(':', '').replace(',', '_').replace('.', '_').replace(\"'\", '').replace('!', '_').replace('?', '').replace('-', '_').replace('(', '').replace(')', '').replace('_a_new_dragon_tattoo_story','').replace('the_equalizer_2','equalizer_2').replace('dr__seuss_the_grinch_2018','the_grinch').replace('disneys_','')\n",
    "        movies[i] = movies[i].lower().replace('___', '_')\n",
    "        movies[i] = movies[i].lower().replace('__', '_')\n",
    "    review_list = list()\n",
    "    name_list = get_movie_name(None, year)[:num]\n",
    "    for movie in movies[:num]:\n",
    "        review = get_review(movie, page_length, length)\n",
    "        if not review or len(review)<5:\n",
    "            try:\n",
    "                review = get_review(movie+f'_{year}', page_length, length)\n",
    "            except:\n",
    "                print('Do not find the movie')\n",
    "        \n",
    "        review_list.append(' '.join(review))\n",
    "    name_review = list(zip(name_list, review_list))\n",
    "    return name_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find top 100 movies in a specific year\n",
    "def movie_from_year(year):\n",
    "        \n",
    "    import requests \n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "    response = requests.get(url)\n",
    "    results = BeautifulSoup(response.content, 'lxml')\n",
    "    results = results.find_all('a')        \n",
    "    \n",
    "    url_list=[]\n",
    "    name_list = []\n",
    "    for result in results:\n",
    "        if result.get('href') != None:\n",
    "            if 'id='in result.get('href') and '#' not in result.get_text():\n",
    "                url_list.append('https://www.boxofficemojo.com'+result.get('href'))\n",
    "                name_list.append(result.get_text())\n",
    "    return url_list,name_list\n",
    "\n",
    "#Find movie urls and names from one year to the other\n",
    "def find_from_to(yearx,yeary):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    list_all_url = []\n",
    "    list_all_name = []\n",
    "    \n",
    "    for year in range(yearx,yeary+1):\n",
    "        url,name = movie_from_year(year)\n",
    "        list_all_url.append(url)\n",
    "        list_all_name.append(name)\n",
    "    \n",
    "    return list_all_url,list_all_name\n",
    "\n",
    "#Find a movie's data with a provided url\n",
    "def movie_data(url):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    response=requests.get(url)\n",
    "    result = BeautifulSoup(response.content,'lxml')\n",
    "    name = ['Name','Domestic Total Gross','Distributor','Release Time','Genre','Runtime','MPAA Rating','Production Budget','Worldwide Gross']\n",
    "    data_list = [item.get_text() for item in result.find_all('b')[1:9]]\n",
    "    data_list.append(result.find_all('b')[13].get_text())\n",
    "    if 'Domestic Lifetime Gross:' in data_list[2]:\n",
    "        data_list = [item.get_text() for item in result.find_all('b')[1:3]]\n",
    "        new_list = [item.get_text() for item in result.find_all('b')[4:10]]\n",
    "        data_list.extend(new_list)\n",
    "        data_list.append(result.find_all('b')[14].get_text())\n",
    "    if '$' not in data_list[-1]:\n",
    "        data_list[-1] = 'N/A'\n",
    "    a = pd.DataFrame(data_list,name)\n",
    "    return np.transpose(a)\n",
    "\n",
    "#Find top 100 movies' data\n",
    "def movie_data_group(year):\n",
    "    \n",
    "    import pandas as pd\n",
    "    url_list,name_list = movie_from_year(year)\n",
    "    list_ = []\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            a = movie_data(url)\n",
    "        except:\n",
    "            continue\n",
    "        list_.append(a)\n",
    "    return pd.concat(list_)\n",
    "\n",
    "#This function is used to draw a pie graph for the feature distributions in top 100 movies.\n",
    "def pie_graph(data,feature):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np  \n",
    "    import matplotlib.mlab as mlab  \n",
    "    import matplotlib.pyplot as plt \n",
    "    new_data = data.groupby(feature).size().sort_values(ascending = False)\n",
    "    label = list(new_data.index)\n",
    "    x = list(new_data)\n",
    "    abc = [(label[i],x[i]) for i in range(len(label))]\n",
    "    ab = abc[:5]\n",
    "    new_label = [item[0] for item in ab]\n",
    "    new_x = [item[1] for item in ab]\n",
    "    new_label.append('Others')\n",
    "    total = [item[1] for item in abc]\n",
    "    new_x.append(sum(total)-sum(new_x))\n",
    "    fig = plt.figure()\n",
    "    plt.axes(aspect=1)\n",
    "    plt.pie(new_x,labels=new_label,autopct='%1.2f%%',shadow= True) \n",
    "    plt.title(feature.capitalize()+\" Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some details need to be adjusted\n",
    "# get_movie_urls: the first item is wrong\n",
    "# data_movies_table: something is wrong when handling with lots of items\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
