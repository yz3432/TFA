{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movalyst:\n",
    "    def __init__(self):\n",
    "        return self\n",
    "    # get all urls for movie list from year x to year y\n",
    "    def get_movie_url(x=1980,y=2018):\n",
    "        import requests \n",
    "        import datetime\n",
    "        from bs4 import BeautifulSoup\n",
    "    \n",
    "        if x > y :\n",
    "            raise ValueError('Start time should be earlier.')\n",
    "        if x < 1980 or y> int(str(datetime.datetime.now())[:4]):\n",
    "            raise ValueError('Please input time during 1980 till now.')\n",
    "    \n",
    "        url = 'https://www.boxofficemojo.com/yearly/'\n",
    "        url_list = []\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        results = BeautifulSoup(response.content, 'lxml')\n",
    "        results = results.find_all('a')\n",
    "    \n",
    "        for result in results:\n",
    "            if 'yr=' in result.get('href') and int(result.get_text())>=x and int(result.get_text())<=y:\n",
    "                url_list.append(url+result.get('href'))\n",
    "        return url_list\n",
    "\n",
    "    def get_movie(url = None, year = None):\n",
    "        import requests \n",
    "        from bs4 import BeautifulSoup\n",
    "        if url == None:\n",
    "            url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "        response = requests.get(url)\n",
    "        results = BeautifulSoup(response.content, 'lxml')\n",
    "        results = results.find_all('a')        \n",
    "    \n",
    "        url_list=[]\n",
    "        for result in results:\n",
    "            if result.get('href') != None:\n",
    "                if 'id='in result.get('href') and '#' not in result.get_text():\n",
    "                    url_list.append('https://www.boxofficemojo.com'+result.get('href'))\n",
    "        return url_list\n",
    "    \n",
    "    def get_movie_name(url = None, year = None):\n",
    "        import requests \n",
    "        from bs4 import BeautifulSoup\n",
    "        if url == None:\n",
    "        url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "        response = requests.get(url)\n",
    "        results = BeautifulSoup(response.content, 'lxml')\n",
    "        results = results.find_all('a')        \n",
    "    \n",
    "        moviename_list=[]\n",
    "        for result in results:\n",
    "            if result.get('href') != None:\n",
    "                if 'id='in result.get('href') and '#' not in result.get_text():\n",
    "                    moviename_list.append(result.get_text())\n",
    "        return moviename_list\n",
    "    \n",
    "    def find_all(x,y):\n",
    "        import requests \n",
    "        from bs4 import BeautifulSoup\n",
    "        list_url = get_movie_url(x,y)\n",
    "        dict_movie = {}\n",
    "        for url in list_url:\n",
    "            list_0 = list_movie.copy()\n",
    "            list_1 = dict(map(lambda x,y:[x,y],get_movie_name(url),get_movie(url)))\n",
    "            dict_movie = {**list_0, **list_1}\n",
    "            return dict_movie\n",
    "    \n",
    "#     def data_movie(year):\n",
    "        \n",
    "#         import requests \n",
    "#         from bs4 import BeautifulSoup\n",
    "#         url = 'https://www.boxofficemojo.com/yearly/chart/?yr='+str(year)+'&p=.htm'\n",
    "#         response = requests.get(url)\n",
    "#         results = BeautifulSoup(response.content, 'lxml')\n",
    "#         results = results.find_all('font',size=\"2\")\n",
    "#         return results\n",
    "    \n",
    "    # get a movie's daily gross\n",
    "    def gross_movie(name,begin_year=1980,end_year=2018):      \n",
    "        import pandas as pd\n",
    "        import requests \n",
    "        from bs4 import BeautifulSoup\n",
    "        try:\n",
    "            movie_url = find_all(begin_year,end_year)[name]\n",
    "            id_position = movie_url.find('id=')\n",
    "            name_id = movie_url[id_position:]\n",
    "            url = 'https://www.boxofficemojo.com/movies/?page=daily&view=chart&'+name_id\n",
    "            response = requests.get(url)\n",
    "            results = BeautifulSoup(response.content, 'lxml')\n",
    "            tables = results.select('table')\n",
    "            df_list = []\n",
    "            for table in tables:\n",
    "                df_list.append(pd.concat(pd.read_html(table.prettify())))\n",
    "            movie_gross = df_list[7]\n",
    "            movie_gross.columns = ['Day','Date','Rank','Gross','%daily-change','%weekly-change','Theaters','Average','Gross-to-Date','Days']\n",
    "            movie_gross = movie_gross[(movie_gross['Date'] != 'Date') & (movie_gross['Date'].notnull())]\n",
    "            movie_gross.set_index('Date',inplace=True)\n",
    "            movie_gross[['Days']] = movie_gross[['Days']].astype(int)\n",
    "            return movie_gross        \n",
    "        except:\n",
    "            ValueError(f'{name} is not in the TOP100  of year from to {begin_year} to {end_year}')\n",
    "    \n",
    "    # get a movie's basic information as a tabel and put the result into a csv\n",
    "    def data_movie(name,begin_year=1980,end_year=2018):      \n",
    "        import pandas as pd\n",
    "        import requests \n",
    "        from bs4 import BeautifulSoup\n",
    "        try:\n",
    "            movie_url = find_all(begin_year,end_year)[name]\n",
    "            response = requests.get(movie_url)\n",
    "            results = BeautifulSoup(response.content, 'lxml')\n",
    "            tables = results.select('table')\n",
    "            df_list = []\n",
    "            for table in tables:\n",
    "                df_list.append(pd.concat(pd.read_html(table.prettify())))\n",
    "            movie_info = {}\n",
    "            movie_info['Name'] = name\n",
    "            movie_info['Genre'] = df_list[5][0].iloc[2][8:]\n",
    "            movie_info['Runtime'] = df_list[5][1].iloc[2][10:]\n",
    "            movie_info['Production Budget'] = df_list[5][1].iloc[3][20:]\n",
    "            movie_info['Release Date'] = df_list[5][1].iloc[1][15:]\n",
    "            movie_info['Close Date'] = df_list[12][1].iloc[0] \n",
    "            movie_info['Inrelease Time'] = df_list[13][1].iloc[0] \n",
    "            movie_info['Widest Release'] = df_list[11][1].iloc[0] \n",
    "            movie_info['Domestic Gross'] = df_list[9][1].iloc[0]\n",
    "            movie_info['Foreign Gross'] = df_list[9][1].iloc[1]\n",
    "            movie_info['Worldwide Gross'] = df_list[9][1].iloc[3]\n",
    "            df_list[14].set_index(0,inplace=True)\n",
    "            try:\n",
    "                movie_info['Director'] = df_list[14][1].loc['Director:']\n",
    "            except:\n",
    "                movie_info['Director'] = df_list[14][1].loc['Directors:']\n",
    "            movie_info['Actors'] = df_list[14][1].loc['Actors:']\n",
    "            try:\n",
    "                movie_info['Producer'] = df_list[14][1].loc['Producer:']\n",
    "            except:\n",
    "                movie_info['Producer'] = df_list[14][1].loc['Producers:']\n",
    "            movie_info['Distributor'] = df_list[5][0].iloc[1][14:]\n",
    "            mv = pd.DataFrame(list(movie_info.items()))\n",
    "            mv.columns = ['Items','basic info']\n",
    "            mv.set_index('Items',inplace=True)\n",
    "#             mv.to_csv(path_or_buf=f'./{name}Basic_info.csv')\n",
    "            return mv\n",
    "        except:\n",
    "            ValueError(f'{name} is not in the TOP100 of year from to {begin_year} to {end_year}')\n",
    "    \n",
    "    \n",
    "    #get a list of movies' information tables and input them into a csv\n",
    "    def data_movies_table(begin_year=1980,end_year=2018,input_name=None):  \n",
    "        if not input_name == None:\n",
    "            name_list = input_name\n",
    "        else:\n",
    "            name_list = list(find_all(begin_year,end_year).keys())\n",
    "        movie_table = data_movie(name_list[0],begin_year,end_year)\n",
    "        for name in name_list[1:]:\n",
    "            try:\n",
    "            movie_info = data_movie(name,begin_year,end_year)\n",
    "            movie_table[name]=movie_info[name]\n",
    "            except:\n",
    "                continue\n",
    "#         mv.to_csv(path_or_buf=f'./{begin_year}-{end_year}some movies basic info.csv')\n",
    "        return movie_table      \n",
    "\n",
    "    def get_review(name, page_length = 2, num = 20):\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        url = 'https://www.rottentomatoes.com/m/'+name+'/reviews/'\n",
    "        response = requests.get(url)\n",
    "        results_page = BeautifulSoup(response.content, 'lxml')\n",
    "        results = results_page.find_all('div', class_ = 'the_review')\n",
    "        page = 1\n",
    "        reviews = list()\n",
    "        next_page_results = list()\n",
    "\n",
    "        while page < page_length:\n",
    "            for item in results_page.find_all('a', class_ = 'btn btn-xs btn-primary-rt'):\n",
    "                if item.find('span', class_ = \"glyphicon glyphicon-chevron-right\"):\n",
    "                    url = 'https://www.rottentomatoes.com' + item.get('href')\n",
    "                    response = requests.get(url)\n",
    "                    results_page = BeautifulSoup(response.content, 'lxml')\n",
    "                    next_page_results = results_page.find_all('div', class_ = 'the_review')\n",
    "            results.extend(next_page_results)\n",
    "            page+=1\n",
    "        for result in results:\n",
    "            reviews.append(result.get_text())\n",
    "\n",
    "        return reviews[:num]\n",
    "\n",
    "    def get_name_review(year, num = 30, page_length = 2, length = 20):\n",
    "        movies = get_movie_name(None, year)\n",
    "        for i in range(len(movies)):\n",
    "            movies[i] = movies[i].lower().replace(' ', '_').replace(':', '').replace(',', '_').replace('.', '_').replace(\"'\", '').replace('!', '_').replace('?', '').replace('-', '_').replace('(', '').replace(')', '').replace('_a_new_dragon_tattoo_story','').replace('the_equalizer_2','equalizer_2').replace('dr__seuss_the_grinch_2018','the_grinch').replace('disneys_','')\n",
    "            movies[i] = movies[i].lower().replace('___', '_')\n",
    "            movies[i] = movies[i].lower().replace('__', '_')\n",
    "        review_list = list()\n",
    "        name_list = get_movie_name(None, year)[:num]\n",
    "        for movie in movies[:num]:\n",
    "            review = get_review(movie, page_length, length)\n",
    "            if not review or len(review)<5:\n",
    "                try:\n",
    "                    review = get_review(movie+f'_{year}', page_length, length)\n",
    "                except:\n",
    "                    print('Do not find the movie')\n",
    "        \n",
    "            review_list.append(' '.join(review))\n",
    "        name_review = list(zip(name_list, review_list))\n",
    "        return name_review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some details need to be adjusted\n",
    "# get_movie_urls: the first item is wrong\n",
    "# data_movies_table: something is wrong when handling with lots of items\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
